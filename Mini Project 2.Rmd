---
title: "Mini Project 2"
author: "Nii Adjetey Adjei-Annan"
date: "2024-03-25"
output: html_document
---

##Problem 1

#1-4
```{r}
set.seed(123)
beta0 = 2
beta1 = 3

n = 100
X = runif(n, min = 0, max = 10) 
sigma = 4
epsilon = rnorm(n, mean = 0, sd = sigma) 

Y = beta0 + beta1 * X + epsilon


SSxy = sum((X - mean(X)) * (Y - mean(Y)))
SSxx = sum((X - mean(X))^2)
beta1_hat = SSxy / SSxx
beta1_hat
beta0_hat = mean(Y) - beta1_hat * mean(X)
beta0_hat
SSE = sum((Y - (beta0_hat + beta1_hat * X))^2)
sigma2_hat = SSE / (n - 2)
sigma2_hat

```


#5-7
```{r}
set.seed(456) 
simulations = 1000
beta0_hats = numeric(simulations)
beta1_hats = numeric(simulations)
sigma2_hats = numeric(simulations)

for (i in 1:simulations) {
  epsilon = rnorm(n, mean = 0, sd = sigma)
  Y = beta0 + beta1 * X + epsilon
  
  SSxy = sum((X - mean(X)) * (Y - mean(Y)))
  SSxx = sum((X - mean(X))^2)
  beta1_hats[i] = SSxy / SSxx
  beta0_hats[i] = mean(Y) - beta1_hats[i] * mean(X)
  SSE = sum((Y - (beta0_hats[i] + beta1_hats[i] * X))^2)
  sigma2_hats[i] = SSE / (n - 2)
}

average_beta0 = mean(beta0_hats)
average_beta0 

average_beta1 = mean(beta1_hats)
average_beta1

average_sigma2 = mean(sigma2_hats)
average_sigma2

bias_beta0 = average_beta0 - beta0
bias_beta0

bias_beta1 = average_beta1 - beta1
bias_beta1

bias_sigma2 = average_sigma2 - sigma^2
bias_sigma2

```

#8
```{r}
hist(beta1_hats, probability = TRUE, main = "beta1_hat with Density Curve")
lines(density(beta1_hats), col = "blue") 

```


#9
```{r}
var_beta1_hat = var(beta1_hats)
var_beta1_hat
```


#10
```{r}
true_var_beta1_hat = sigma^2 / SSxx
true_var_beta1_hat

```


#11
```{r}
# Since the empirical variance [var_beta1_hat(0.02020941)] is closer to the theoretical variance [true_var_beta1_hat(0.019898)] we can conclude that our simulation process is more accurate. 
```


##Problem 2

#1-5
```{r}
set.seed(110)
beta0 <- 1
beta1 <- 2
beta2 <- -1
beta3 <- 0.5
sigma <- 5

n = 500
x1 = rnorm(n, 10, 5)
x2 = runif(n, 0, 20)
x3 = rnorm(n, 5, 2)

epsilon = rnorm(n, 0, sigma)
Y.1 = beta0 + beta1*x1 + beta2*x2 + beta3*x3 + epsilon


X.1 = cbind(1, x1, x2, x3) 
beta_hat = solve(t(X.1) %*% X.1) %*% t(X.1) %*% Y.1
beta_hat

Y_hat = X.1 %*% beta_hat
e = Y.1 - Y_hat
SSE1 = sum(e^2)
SSE1
sigma2_hat = SSE1 / (n - (3 + 1)) 
sigma2_hat




```



#6
```{r}
var_beta_hat1 = sigma2_hat * solve(t(X.1) %*% X.1)
var_beta_hat1

```


#7
```{r}
se_beta_hat = sqrt(diag(var_beta_hat1))
t_critical = qt(0.975, n - 4)

CI_beta1 = beta_hat[2] + c(-1, 1) * t_critical * se_beta_hat[2]
CI_beta1
CI_beta2 = beta_hat[3] + c(-1, 1) * t_critical * se_beta_hat[3]
CI_beta2
CI_beta3 = beta_hat[4] + c(-1, 1) * t_critical * se_beta_hat[4]
CI_beta3

```



#8
```{r}
model1 = lm(Y.1 ~ x1 + x2 + x3)
summary(model1) 

#The fitted lm model1 (model1) compared to the simulated data gives the same value for estimated B0, B1, B2 and B3. From the estimated sigma_hat (27.06) calculated we can get residual standard error by taking square root of Sigma_hat, this value is the same as the residual standard error given by the fitted lm model(model1)


```

#9
```{r}

SSE1

SSR = sum((Y_hat - mean(Y_hat))^2)
SSR

SST = sum((Y.1 - mean(Y.1))^2)
SST

relationship_verified = round(SSE1 + SSR)==round(SST)
relationship_verified 



```

#10
```{r}
k = 3 
MSE = SSE1 / (n - (k + 1))
MSR = SSR / k
F_statistic = MSR / MSE
F_statistic

```


#11
```{r}
p_value_F_test = pf(F_statistic, df1 = k, df2 = n - (k + 1), lower.tail = FALSE)
p_value_F_test 


#An F staitistics of 801.7895 and a p-value of zero, implies that we strongly reject the null hypothessis and conclude that the differences among group means are statistically significant, indicating a strong effect of the independent variable(s) on the dependent variable.
```


#12

```{r}
R2_adj <- 1 - ((SSE1 / (n - (k + 1))) / (SST / (n - 1)))
R2_adj
#Approximately 83% of the variation in the dependent variable (Y) is explained by the regressors (X)
```

#13
```{r}

summary_model = summary(model1)
summary_model

anova_model =  anova(model1)
anova_model

```



##Problem 3
#1-3
```{r}
simulate_mlr = function(n, iterations = 1000) {

  beta0 = 1
  beta1 = 2
  beta2 = -1
  beta3 = 0.5
  sigma = 5
  
 
  estimates = matrix(0, nrow = iterations, ncol = 3)
  CIs = array(0, dim = c(iterations, 3, 2))
  true_betas = c(beta1, beta2, beta3)
  
  for (i in 1:iterations) {
    
    x1 = rnorm(n, mean = 10, sd = 5)
    x2 = runif(n, min = 0, max = 20)
    x3 = rnorm(n, mean = 5, sd = 2)
    epsilon = rnorm(n, mean = 0, sd = sigma)
    Y = beta0 + beta1 * x1 + beta2 * x2 + beta3 * x3 + epsilon

    
    X = cbind(1, x1, x2, x3)
    beta_hat = solve(t(X) %*% X) %*% t(X) %*% Y
    estimates[i, ] = beta_hat[2:4]

    
    Y_hat = X %*% beta_hat
    residuals = Y - Y_hat
    SSE = sum(residuals^2)
    sigma2_hat = SSE / (n - 4)
    var_beta_hat = sigma2_hat * solve(t(X) %*% X)
    
    for (j in 1:3) {
      se = sqrt(diag(var_beta_hat)[j+1])
      t_critical = qt(0.975, df = n - 4)
      CIs[i, j, ] = c(beta_hat[j+1] - t_critical * se, beta_hat[j+1] + t_critical * se)
    }
  }


  biases = colMeans(estimates) - true_betas
  coverage = colMeans(CIs[, , 1] <= true_betas & CIs[, , 2] >= true_betas)
  
  list(biases = biases, coverage = coverage)
}


```


#4-5
```{r}
results_500 = simulate_mlr(500)
results_500
results_750 = simulate_mlr(750)
results_750
results_1000 = simulate_mlr(1000)
results_1000
```

#6
```{r}

data = data.frame(
  n = c(500, 750, 1000),
  Bias_Beta1 = c(0.0006756336, -0.0001264552, -0.0016542234),
  Coverage_Beta1 = c(0.317, 0.323, 0.320),
  Bias_Beta2 = c(0.0015435055, -0.0001052672, 0.0009652531),
  Coverage_Beta2 = c(0.320, 0.318, 0.324),
  Bias_Beta3 = c(0.0047427018, -0.0015830796, -0.0036426610),
  Coverage_Beta3 = c(0.321, 0.311, 0.322)
)


print(data)


```










